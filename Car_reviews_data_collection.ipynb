{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "options = Options()\n",
    "options.headless = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new .csv file that the data will be written to\n",
    "csv_file = open('KiaSeltosCarReviews.csv', 'w', encoding=\"UTF-8\", newline=\"\")\n",
    "writer = csv.writer(csv_file)\n",
    "\n",
    "# Define the variables (future data frame columns) to be scraped\n",
    "writer.writerow(['Customer Name' , 'Review text' , 'Review date' , 'Review Star-Rating', 'Review Website'])\n",
    "\n",
    "#Invoking the webdriver\n",
    "driver = webdriver.Chrome(options=options, executable_path=r'C:/Users/nisha/Desktop/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Find total number of reviews posted on cardekho.com\n",
    "    # Each page defaults to showing 30 reviews, so take the ceiling of the total number of job postings divided by 30\n",
    "    # to get the number of pages\n",
    "    page=\"https://www.cardekho.com/kia/seltos/user-reviews\"\n",
    "    driver.get(page)\n",
    "    time.sleep(5)\n",
    "    total = driver.find_element_by_xpath('//div[@class =\"startRating\"]//span[@class=\"bottomText\"]').text\n",
    "    n = int(ceil(float(total.split()[0])/30))\n",
    "    print(n)\n",
    "    k = 1  \n",
    "    while k <= n: # Initializing k with 1 and looping it till it exhausts all the pages \n",
    "        print(\"Scraping \" + \"page : \" + str(k))  # Printing the page no which is being scraped\n",
    "        try:\n",
    "            p = 1\n",
    "            # Fetching the handle for all the reviews available on the page opened by the driver\n",
    "            Reviews = driver.find_elements_by_xpath('//div[@class=\"readReviewBox\"]')\n",
    "            for review in Reviews: # Taking one review at a time to extract the info\n",
    "                print(\"Scraping \" + \"review #\" + str(p) + \" of page : \" + str(k))\n",
    "                p = p + 1\n",
    "                reviews_dict = {}       # Creating an empty dictionary by the name \"reviews_dict\"\n",
    "                try:\n",
    "                    #Fetching Reviewer_Name\n",
    "                    Name = review.find_element_by_xpath('.//div[@class =\"authorSummary\"]//div[@class = \"name\"]').text\n",
    "                    Reviewer_Name = ' '.join(Name.split()[1:])\n",
    "                except:\n",
    "                    Reviewer_Name = \"\"\n",
    "                try:\n",
    "                    #First fetching the link where full review text and website name is embedded\n",
    "                    #Opening the fetched link with the help of driver and then storing the review text\n",
    "                    Opening_link = review.find_element_by_xpath('.//div[@class =\"contentspace\"]//h3//a').get_attribute('href')\n",
    "                    driver1 = webdriver.Chrome(options=options, executable_path=r'C:/Users/nisha/Desktop/chromedriver.exe')\n",
    "                    driver1.get(Opening_link)\n",
    "                    time.sleep(3)\n",
    "                    Review_text = driver1.find_element_by_xpath('.//p[@class =\"contentheight\"]').text\n",
    "                except:\n",
    "                    Review_text = \"\"\n",
    "                try:\n",
    "                    #Fetching the name of website on which the review is posted\n",
    "                        Review_Website = driver1.title.split()[-1]\n",
    "                        driver1.close()\n",
    "                except:\n",
    "                    Review_Website = \"\"\n",
    "                try:\n",
    "                    #Fetching the review date of the review\n",
    "                    Date = review.find_element_by_xpath('.//div[@class =\"date\"]').text\n",
    "                    Review_date = ''.join([date for date in Date.split()[1:4]])\n",
    "                except:\n",
    "                    Review_date = \"\"\n",
    "                try:\n",
    "                    #Fetching the rating provided by the reviewer\n",
    "                    elem = review.find_elements_by_css_selector(\"span[class ^= 'stars']\")\n",
    "                    x = {'full-fill' : 1 , 'half-empty' : 0.5 ,'full-empty' : 0 }\n",
    "                    Review_Star_Rating = sum([x['-'.join(elem[i].get_attribute(\"class\").split()[2].split('-')[-2:])] for i in range(0,5)])\n",
    "                except:\n",
    "                    Review_Star_Rating = \"\"     \n",
    "                \n",
    "                # Write the results of the above to a dictionary. Note that each review will have its\n",
    "                # own dictionary, but all dictionaries for all the rows will all have the same keys. This\n",
    "                # allows Selenium to write the contents of these dictionaries into a coherent .csv file    \n",
    "                reviews_dict['Customer Name'] = Reviewer_Name\n",
    "                reviews_dict['Review text'] = Review_text\n",
    "                reviews_dict['Review date'] = Review_date\n",
    "                reviews_dict['Review Star-Rating'] = Review_Star_Rating\n",
    "                reviews_dict['Review Website'] = Review_Website\n",
    "                writer.writerow(reviews_dict.values())\n",
    "                \n",
    "    \n",
    "            driver.close()\n",
    "            k = k+1\n",
    "            try :\n",
    "                driver = webdriver.Chrome(options=options, executable_path=r'C:/Users/nisha/Desktop/chromedriver.exe')\n",
    "                page=\"https://www.cardekho.com/kia/seltos/user-reviews\"  +\"/\" + str(k) +\"?\" + \"subtab=latest\"\n",
    "                driver.get(page)\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                break\n",
    "        # If an error is thrown unrelated to the above variables, print the error to the terminal\n",
    "        # console, close the .csv file, and break the while loop.\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            csv_file.close()\n",
    "            driver.close()\n",
    "            break\n",
    "            \n",
    "# If an error is thrown unrelated to the above variables, print the error to the terminal\n",
    "# console, close the .csv file, and break the while loop.           \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    csv_file.close()\n",
    "    driver.close()\n",
    "\n",
    "#Closing the csv file and the driver that has been opened\n",
    "csv_file.close()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the link we can obtain the reviews data for rest of the two cars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
